# ETL_Python
Proyecto que utiliza técnicas de scraping, limpieza, y visualización de datos

Se distribuyó el proyecto en varias notebooks para detallar mejor el paso a paso
En primera instancia se realizó un scraping utilizando BeautifulSoup para obtener los datos más importantes incluyendo todas las publicaciones del sitio y guardarlos en un dataframe.
Luego usando Python damos forma a  un dataframe mejor estructurado  y usamos Pandas para su limpieza y normalización.
Ya limpios con ayuda de un código externo hecho en Google Sheets complementamos la información y reducimos el dataframe a uno con mejor calidad de datos.
Con la ayuda de Matplotlib  sacamos las primeras conclusiones y preparamos el archivo para su análisis profundo y damos los últimos detalles para someterlo a pruebas de machine learning.

